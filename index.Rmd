---
title: "Computational Musicology"
author: "DaniÃ«l Vermaas"
date: "`r Sys.Date()`"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    css: styles.css
    source_code: https://github.com/dvermaas/ComputationalMusicology
    self_contained: false
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Modules to import
library(dplyr)
library(ggplot2)
library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
library(grid)
library(gridExtra)
library(ggpubr)
library(cowplot)
library(showtext)
library(ggdendro)
library(heatmaply)
library(tidymodels)

# Custom font
font_add("TTNorms", "TTNorms-ExtraBold.otf")
showtext_auto()
```

```{r, include=FALSE}
# Load corpus playlist from Spotify API
corpus <- get_playlist_audio_features("", "75c0U5PruEBXAONbvVjHBH") %>%
  mutate(mode = ifelse(mode == 0, "Minor", "Major")) %>% 
  mutate(artists.name = map_chr(track.album.artists, function(x) x$name[1]))

# Fixing error in artist.name mutation
corpus$artists.name[corpus$artists.name == "Artemis Rising"] <- "Downtown Binary"
```

```{r, include=FALSE}
# Define your own theme function below
theme_vapor <- function() {
    theme_minimal() +
    theme(
      text = element_text(family = "TTNorms", color = "#eb34b1", size=14),
      plot.title = element_text(hjust = 0.5),
      plot.background = element_rect(fill = "#181818", color="#181818"),
      panel.background  = element_rect(fill = "#121212"),
      legend.key = element_rect(fill = "#181818"),
      #legend.background = element_rect(fill = "#131313")
      panel.grid = element_line(color = "#eb34b1")
    )
}

# Fixing weird legend formatting: https://stackoverflow.com/questions/49133395/strange-formatting-of-legend-in-ggplotly-in-r
ggplotfix <- function(myplot){
  for (i in 1:length(myplot$x$data)){
    if (!is.null(myplot$x$data[[i]]$name)){
        myplot$x$data[[i]]$name =  gsub("\\(","",str_split(myplot$x$data[[i]]$name,",")[[1]][1])
    }
  }
  return(myplot)
}

# KNN support functions
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  
```

### Introduction: Corpus Description {data-commentary-width="400"}

**What is your corpus, why did you choose it, and what do you think is
interesting about it?**

Synthwave (also called outrun, retrowave, or futuresynth) is an
electronic music microgenre that is based predominantly on the music
associated with action, science-fiction, and horror film soundtracks of
the 1980s. Other influences are drawn from the decade's art and video
games. Synthwave musicians often espouse nostalgia for 1980s culture and
attempt to capture the era's atmosphere and celebrate it. (from
Wikipedia)

I chose this corpus because I am currently listening to a lot of
synthwave music. I also listen to all my music on Spotify, so I can use
my playlists to build my corpus up quickly. I am also currently working
on a synthwave rhythm-game in unity, so exploring this corpus could also
help with this side project.

I have selected the following artists, which should represent the
following subgenres:

-   Downtown binary: chill-synth
-   Jan Hammer: soundtrack synth
-   The midnight: pop/dance synth
-   Home: Vaporwave
-   Carpenter Brut: Hardcore-ish synth

**What are the natural groups or comparison points in your corpus and
what is expected between them?**

I intend to divide the corpus based on subgenres within synthwave. These
subgenres are similar to the subgenres within heavy metal, but likely a
lot more subtle. It would therefore be interesting to see if these
subgenres are actually detectable within the corpus. I personally do not
think there are very significant differences between most of these
subgenres, but we will see if the data agrees with that statement. I
want to approach this by selecting five of the most different
synthwave-artists I enjoy listening to, and by looking if these
differences are perceivable by the music-visualization methods mentioned
during the course.

**How representative are the tracks in your corpus for the groups you
want to compare?**

I will use a couple of playlists for each artist to build the corpus,
making sure all artists take up an (close to) equal share of the corpus.
This will ensure that all artists are equally represented. For subgenre
detection representativeness is debatable. It is almost universally
agreed upon that Home is one of the OG's of Vaporwave. Jan Hammer is
also a very respected soundtrack artist in the scene. The other genres
are probably more debatable. But the same goes for the more niche
subgenres of hardcore rock, so I believe the experiment will still be
compelling.

**Identify several tracks in your corpus that are either extremely
typical or atypical. Why do you think that they are so typical or so
strange?**

Turbo Killer by Carpenter Brut is one atypical outlier. It is by far the
most intense/speedy track in the entire corpus, even by Carpenter Brut
standards. I also think that Resonance from Home may be an outlier. It
has very odd sounds, even for vaporwave standards, I do not think there
is anything that sounds close to this track. Respirate (Downtown Binary
Remix) is the final outlier in this corpus. This is obviously because it
is a remix of a song not originally created by Downtown Binary, but I
think it still retains the Downtown Binary style, therefore I expect it
to be interesting in analysis.

**Source & Reproducibility**

The whole project uses Spotify API as the source, and by hitting the
Github "Source code" button, all code used to generate all
visualizations can be verified on accuracy and methodology.

***

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/75c0U5PruEBXAONbvVjHBH?utm_source=generator" width="100%" height="280" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/58spcwLelMvMpKvObWuwbN?utm_source=generator" width="100%" height="280" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

**About the playlists**

The corpus playlist contains all the tracks used in analysis. I chose to
also include the old corpus, because it has a much greater listening
experience. It contains a lot more variety taking the best songs from
each album, while the new corpus includes more albums in their entirety.

### Corpus distribution {data-commentary-width="400"}

```{r, echo = FALSE}
p1 <- ggplot(corpus, aes(track.popularity)) + geom_histogram(bins=50, fill = "#ff6c11") +
  labs(
  x="Popularity",
  y="Count",
  title="Popularity distribution of the corpus",
  caption="Source: Spotify API") +
  xlim(0,100) +
  theme_vapor()

p2 <- ggplot(corpus, aes(speechiness)) + geom_histogram(bins=50, fill = "#f9c80e") +
  labs(
  x="Speechness",
  y="Count",
  title="Speechness distribution of the corpus",
  caption="Source: Spotify API") +
  xlim(0,1) +
  theme_vapor()

# subplot titles: https://stackoverflow.com/questions/37285729/how-to-give-subtitles-for-subplot-in-plot-ly-using-r
subplot(ggplotly(p1), ggplotly(p2)) %>% 
  layout(title = '', showlegend = FALSE) %>% 
  layout(annotations = 
           list(list(x = 0.15 , y = 1.05, text = "Popularity distribution of the corpus",
                     showarrow = F, xref='paper', yref='paper'),
                list(x = 0.85 , y = 1.05, text = "Speechness distribution of the corpus", 
                     showarrow = F, xref='paper', yref='paper'))
)
```

***

**The basics**

When working with a new dataset, it is often a great idea to create some
basic plots to get a feeling for the dataset, before diving into the
actual research. The following two histograms will hopefully give a
crude visualization of some properties of the chosen corpus.

**Low popularity**

Lets start of by looking at the popularity of the songs in the matrix.
Spotify API assigns a popularity value to each track from 0 to 100. We
can see that most songs have about 50 popularity. With some outliers
close to minimum and maximum popularity. The corpus has a surprising
amount of popularity while not being a well known genre (or maybe it
is?). It would be nice if Spotify would explain how it determines
popularity.

**Low Speechness**

It is clear from this histogram that speechness is very low in the
corpus. This makes a lot of sense, because most tracks in the corpus do
not contain any vocals. What the plot does show us is that the expected
speechness values and the Spotify provided values do indeed match up,
which is good.

### Energy & Valence {data-commentary-width="400"}

```{r, echo = FALSE} 
#instumental acoustic
p <- ggplot(corpus, aes(valence, energy, size = loudness, label = track.name, color = artists.name)) +
  geom_point(alpha=.6) +
  scale_fill_discrete() +
  labs(
  x="Valence",
  y="Energy",
  title="Vibe & Volume analysis",
  caption="Source: Spotify API",
  color = "Artist(s)                       ",
  size = "") +
  xlim(0,1) + 
  ylim(0,1) +
  theme_vapor()

ggplotfix(ggplotly(p))
```

***

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1Zm2rsEmqIz8KaWLvtvWA3?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

**Vibe checking**

Energy and Valence can convey the mood of songs. Active songs will have high
energy, while passive tracks will have low energy. In the plot we can clearly see
that almost all of the tracks within the corpus have high energy. We can see clearly that
almost all songs have high energy, with Carpenter Brut having the
highest average energy. Jan Hammer also seems to have the highest
valence tracks. The song with the lowest energy is Night Talk, which has
the low energy score of 0.258. 

Valence determines positivity and negativity, with high valence being positive.
As opposed to energy, the corpus does contain more valence variety, but on average does
have low valence. Boat party having the highest valence score of 0.96. This combination of low valence 
high energy would map to 'nervous'. While this is definitely how I would describe Carpenter Brut, 
The Midnight and Downtown Binary do not sound nervous, so simply classifying vibe by these metrics may 
be naive. Carpenter Brut also has high loudness for example, which likely contributes to the nervous vibe. 
That being said, Jan Hammer being classified as the most positive does does concur with my own interpretation.

**Classification**

It is good that most songs of each artist do hover around the same valence and energy, meaning
that these two features already give great information about the artists. There is unfortunately a lot of
overlap between the artists. This means that this data is probably not enough on its own to
guess the artist for any given song. While that is a shame, there are a lot of other features like loudness
that can be used to add additional dimensions to the data, so this result still looks very promising.

### Linear Loudness {data-commentary-width="400"}

```{r, echo = FALSE}
p <- ggplot(corpus, aes(loudness, energy, label = track.name)) +
  geom_point(data = corpus, alpha=.6, aes(size = loudness, color = artists.name)) +
  scale_fill_discrete() +
  geom_smooth(method = "lm", se = FALSE, color = "#2DE2E6") +
  labs(
  x="Loudness",
  y="Energy",
  title="Loudness Linearity",
  caption="Source: Spotify API",
  color = "Artist(s)                       ",
  size = "") +
  ylim(0,1) +
  theme_vapor()

ggplotfix(ggplotly(p))
```

***

**Exploring loudness further**

Having observed the previous plot, it looked like there may be some relationship between
energy and loudness. To check if this is indeed true, here we have Loudness and energy plotted,
and fitted with a line afterwards. While there are definitely outliers, we do indeed clearly see that these
features do indeed exhibit a linear relation. Spotify is not very open about how it determines
it's feature values, but using this plot we do get more of an idea how energy is calculated.

### Dynamic Time Warping {data-commentary-width="400"}

```{r, echo = FALSE}
## Crockett's Theme - Jan Hammer
crock_original <-
  get_tidy_audio_analysis("3TnJ7M6in8Pb5EyGBUK02Y") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

## Crockett's Theme - Jan Hammer
crock_remaster <-
  get_tidy_audio_analysis("5srgpROEtK8KLKQl5FW7Ub") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)


dynamic_timewarp <- compmus_long_distance(
  crock_original %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  crock_remaster %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Crockett's Theme - Jan Hammer", y = "Crockett's Theme (remaster) - Jan Hammer", 
       title = "Dynamic Timewarp") +
  theme_vapor() + 
  scale_fill_viridis_c(guide = NULL)

# Fixing white backdrop: https://stackoverflow.com/questions/57051313/coord-map-of-ggplot2-ignores-plot-background-and-produces-white-margins-how
gt <- ggplotGrob(dynamic_timewarp)
grid.newpage()
grid.draw(rectGrob(gp = gpar(fill = "#181818", col = "#181818")))
grid.draw(gt)
```

***

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/3TnJ7M6in8Pb5EyGBUK02Y?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/5srgpROEtK8KLKQl5FW7Ub?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

**Comparing original to remaster**

Jan Hammer's most iconic soundtrack has to be 'Crockett's Theme' from
Miami Vice. Miami Vice is quite old now (originally aired in 1984), but
Jan Hammer's work on the soundtrack is great, and went on to inspire a
lot of the modern Synthwave artists. Jan Hammer recently (2018) released
a remaster of 'Crockett's Theme' in the 'Special edition' album. I like
this remaster better, but it is very subtly different from the original.
Therefore it is probably the perfect candidate for this comparison.

**Analysis**

The plot shows that the original and the remastered soundtrack are
indeed very similar.

### Self Similarity Matrix: Chroma and Timbre {data-commentary-width="400"}

```{r, echo = FALSE}
turbokiller <-
  get_tidy_audio_analysis("10qbHF920zH5K8C8IcE5AL") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )

turbokiller_plot <- bind_rows(
  turbokiller %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  turbokiller %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "C") +
  theme_vapor() + theme(strip.text = element_text(color = "#eb34b1"), panel.background  = element_rect(fill = "#121212", color="#121212")) + 
  labs(x = "", y = "", title = "Turbo Killer - Carpenter Brut")


resonance <-
  get_tidy_audio_analysis("65r94rVdiMwqXyQFEr3tqT") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )

resonance_plot <- bind_rows(
  resonance %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  resonance %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "C") +
  theme_vapor() + theme(strip.text = element_text(color = "#eb34b1"), panel.background  = element_rect(fill = "#121212", color="#121212")) + 
  labs(x = "", y = "", title = "Resonance - Home")

#turbokiller_plot
#plot_grid(p, p, hjust="outward", heights=c(2,4),ncol=1, nrow=2) #5,7
gt <- grid.arrange(turbokiller_plot, resonance_plot, ncol=1)
grid.draw(rectGrob(gp = gpar(fill = "#181818", col = "#181818")))
grid.draw(gt)
```

***

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/10qbHF920zH5K8C8IcE5AL?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/65r94rVdiMwqXyQFEr3tqT?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

**Turbo Killer Analysis**

I wanted to explore the song 'Turbo Killer' by 'Carpenter Brut'. This
song really stands out for quick pacing and constantly building and
escalating upon the previous 'verse'. The song gives a sense of
progression or fast movement/speed, and that is probably why this is one
of my favorite tracks in this corpus.

When looking at the Chroma matrix we see a lot of tiny changes in the
first forty seconds. Every seven-ish seconds there is a change. After 40
seconds the song changes into high tempo guitar only, and the following
blocks all add additional elements to this. The matrix turns out very
interesting, because you can see how the song constantly builds up to
more complexity.

The Timbre matrix looks less interesting. There are no real verses, but
you can tell where transitions to more complexity happen. What is very
surprising is that the high point of the timbre matrix is at the end of
the song.

**Resonance Analysis**

yes

**Comparing**

dissimilar

### Chordogram {data-commentary-width="400"}

```{r, echo = FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}
#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)
major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)
chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )
key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
daysofthunder <-
  get_tidy_audio_analysis("6tJPdGKrbAeyhkkhn44RHR") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
daysofthunder_plot <- daysofthunder %>% 
  compmus_match_pitch_template(
    key_templates,
    method = "euclidean",
    norm = "manhattan"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title="Days of thunder - The Midnight")  + theme_vapor()

aboveall <-
  get_tidy_audio_analysis("7ySSQhz1O7otIcgyOIdRUY") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
aboveall_plot <- aboveall %>% 
  compmus_match_pitch_template(
    key_templates,
    method = "euclidean",
    norm = "manhattan"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title="Above All - Home") + theme_vapor()

subplot(ggplotly(daysofthunder_plot), ggplotly(aboveall_plot), nrows = 2, margin = 0.05, shareX = TRUE, shareY = TRUE) %>% 
  layout(title ='') %>% 
  layout(annotations = 
           list(list(x = 0.5 , y = 1.07, text = "Days of thunder - The Midnight",
                     showarrow = F, xref='paper', yref='paper'),
                list(x = .5 , y = .49, text = "Above All - Home",
                     showarrow = F, xref='paper', yref='paper')))
```

***

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/6tJPdGKrbAeyhkkhn44RHR?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7ySSQhz1O7otIcgyOIdRUY?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

**Chord Analysis**

I have chosen Days of Thunder & Above All from to corpus to do
chordogram analysis with. Both tracks are very consistent in their sound,
which should mean both will have long stretches of the same chord. This is
something that is represented in the plot, both songs have long blocks where the
same chord is being played.

Both songs seem to start with more rapid chord changes, long stretches in the middle,
and then more rapid chord changes in the end. What is surprising is that Days of Thunder
seemingly has a single very long chord block starting at around 80 seconds and ending at
180 seconds. On closer inspection this does consist of two blocks split around 130 seconds,
but when listening to the song I do hear differences within the track. This is apparently not
enough to be represented with significance within the plot. At 180 seconds the chords slightly 
change, which is audible when listening to the song, but it is only slightly different according to the graph.

**Verdict**

It is odd that Above All has more chord changes according to the graph, while being much less complex when
listening to the track. Chord analysis may not be the greatest way to classify tracks, that or these
specific tracks did not work great with chord analysis.

### Tempogram {data-commentary-width="460"}

```{r echo=FALSE}
p1 <- get_tidy_audio_analysis("6641RMUKoXHPVABNIJLZwm") %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Nexus - Downtown Binary") +
  theme_vapor()
ggnexus <- 

p2 <- get_tidy_audio_analysis("5PlZbtB1Ok46sKyjKEfppR") %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Hang'em All - Carpenter Brut") +
  theme_vapor()

subplot(ggplotly(p1), ggplotly(p2), nrows = 2, margin = 0.05, shareX = TRUE, 
        shareY = TRUE, titleY = TRUE) %>% layout(title = '') %>% 
  layout(annotations = 
           list(list(x = 0.5 , y = 1.07, text = "Nexus - Downtown Binary",
                     showarrow = F, xref='paper', yref='paper'),
                list(x = .5 , y = .49, text = "Hang'em All - Carpenter Brut",
                     showarrow = F, xref='paper', yref='paper'))
)
```

***

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/6641RMUKoXHPVABNIJLZwm?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/5PlZbtB1Ok46sKyjKEfppR?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
```

**Tempo Analysis**

Nexus from Downtown Binary gives some interesting results in tempo
analysis, it has three very distinctive phases.The intro phase takes the
first 90 seconds of the song, and has very fluctuating tempo. We get a
very noisy tempogram here. After this the second phase lasts until 115
seconds and has more clearly defined BPM, as it slowly bridges the intro
and third phase. The third phase has a very clear 105 BPM line and a
less clear 158 BPM line.

Hang'em all is an interesting song to compare with Nexus, Because Nexus
is more chill, while Carpenter Brut's Hang'em all is more
powerful/aggressive. Hang'em contains both high and low intensity
sections. The first 50 seconds of the track start intense, followed by a
low intensity subsection. You can clearly observe this in the Tempo
plot, which becomes less noisy and a more consistent line after these
first 50 seconds. From 85 to 120 seconds there is a more intense
subsection, followed by low intensity that blends into high, which is
unexpected, because the whole section looks like the first 50 seconds of
the low intensity track section.

**Comparing**

Hang'em all consistently has higher BPM compared to Nexus, which was to
be expected. While Hang'em all does contain relaxed parts, it always
feels more faster paced than Nexus. The lowest intensity/buildup phases
of both seem to have BPM's that are not clearly defined by the plot, but
when the main parts of both songs happen the BPM line becomes very sharp
and accurate. Average BPM seems to be a reasonable and usable statistic
to differentiate between Carpenter Brut and Downtown Binary.

### Machine Learning using KNN {data-commentary-width="400"}

```{r echo=FALSE}
indie_features <-
  corpus %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(artists.name),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```

```{r echo=FALSE}
indie_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = indie_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].

indie_cv <- indie_features %>% vfold_cv(5)
```

```{r echo=FALSE}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")

synth_forest <- 
  workflow() %>% 
  add_recipe(indie_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    indie_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```

```{r echo=FALSE}
p1 <- workflow() %>% 
  add_recipe(indie_recipe) %>% 
  add_model(forest_model) %>% 
  fit(indie_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col(fill = "#2DE2E6") + 
  coord_flip() +
  labs(x = NULL, y = "Importance") + 
  theme_vapor()

p2 <- synth_forest %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  aes(title = "Random Forest Truthtable") +
  theme_vapor() + 
  scale_fill_gradient(low = "#261447", high = "#2DE2E6")

subplot(ggplotly(p1, legend = FALSE), ggplotly(p2), nrows = 1, margin = 0.06, titleX = TRUE, titleY = TRUE) %>% 
  layout(title = '', showlegend = FALSE) %>%
  layout(annotations = 
           list(list(x = 0.15 , y = 1.05, text = "Most Important Features",
                     showarrow = F, xref='paper', yref='paper', size = 22/.pt),
                list(x = 0.85 , y = 1.05, text = "Random Forest Truth Table", 
                     showarrow = F, xref='paper', yref='paper', size = 14/.pt))
  )
```


***

**Random Forest**

After all previous analysis, it is finally time to see if the
research-question indeed holds true. Initially KNN was used, but after
testing Random Forest reported much better results in validation. Validation
is done using K-fold validation, using 5 partitions. This means
that we train the model on 80% of the data and validate on the remaining
20%. This is then repeated until all 20% slices of the corpus have been
in the validation partition once, giving a more honest non-cherry-picked
representation of the results.

**Important Features**

Loudness is the most important feature for the Random Forest Classifier when
classifying the corpus. This is not fully blindsiding, because in the Linear Loudness
plot we already saw great separation between the labels. Timbre feature #1, which also
represents loudness, is second. It is eye-opening that energy and valence are reasonably
low, I did expect these features to be greater descriptors of the labels.

**Results**

When interpreting the results, one should keep in mind that the maximum
score is 20, since the corpus has 20 entries of each artist. It is obvious 
that the Random Forest Classifier is very accurate when predicting artist. It achieves
the best results with Carpenter Brut, which is likely due to the fact that it
contrasts the most compared to the other artists. It also performs decent on 
Jan Hammer and The Midnight. Downtown Binary and Home seem to be more difficult.

### Conclusion {data-commentary-width="400"}

**The Questions**

The goal of this corpus analysis was to test if subgenre detection within
the synthwave genre would be possible. To test this five synthwave artists
were selected that embody a subgenre. To test this we have used several
music visualizations to compare the differences between the artists, to find
features that may be significant when training a classifier.

**The Answers**

Many of the music visualizations have shown that while all artists belong in the
synthwave genre, their songs are still distinct enough to be accurately distinguished
between. The Loudness plot and the tempogram for example show clear differences between
tracks of different artists.

The Random Forrest classifier proofs the observations made throughout the weeks, many of the
significant features are indeed those that were previously identified. The performance of the
classifier is also incredible, implying that subgenre detection within the synthwave genre may
be more possible then I expected.

**Reflections**

Internal validity etc.

***

**Signing out**

Thank you for reading my music analysis!